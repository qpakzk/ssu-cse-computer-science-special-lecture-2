{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컴퓨터공학특강 2 - 과제 1 : Linear Regression \n",
    "\n",
    "> Numpy 라이브러리로 제공해주는 Batch 처리 방식이 아닌 반복문을 이용하여 Linear Regression을 구현하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function (손실함수)\n",
    "\n",
    "\\begin{equation*}\n",
    "E(W, b) = \\frac{1}{n} \\sum_{i=1}^n [t_i - (Wx_i + b_i)]^2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y = np.zeros_like(t, dtype=float)\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            for k in range(W.shape[0]):\n",
    "                y[i][j] += x[i][k] * W[k][j] + b\n",
    "\n",
    "    diff_sum = 0\n",
    "    for i in range(len(t)):\n",
    "        diff_sum += (t[i] - y[i]) ** 2\n",
    "\n",
    "    return diff_sum / len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Algorithm (경사하강법)\n",
    "\n",
    "\\begin{equation*}\n",
    "W = W - \\alpha\\frac{\\partial E(W, b)}{\\partial W}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "b = b - \\alpha\\frac{\\partial E(W, b)}{\\partial b}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Derivative (수치미분)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.shape[0]):\n",
    "        tmp_val = float(x[idx])\n",
    "        x[idx] = tmp_val + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Function\n",
    "\n",
    "Loss function의 값을 계산하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x, t):\n",
    "    y = np.zeros_like(t, dtype=float)\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            for k in range(W.shape[0]):\n",
    "                y[i][j] += x[i][k] * W[k][j] + b\n",
    "\n",
    "    diff_sum = 0\n",
    "    for i in range(len(t)):\n",
    "        diff_sum += (t[i] - y[i]) ** 2\n",
    "\n",
    "    return diff_sum / len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Function\n",
    "\n",
    "Learning를 마친 후, 미지의 데이터에 대한 미래값 예측 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    if isinstance(x, int) or isinstance(x, float):\n",
    "        x = np.array([x]).reshape(1, 1)\n",
    "    elif isinstance(x, np.ndarray) and len(x.shape) == 1:\n",
    "        x = np.array([x]).reshape(x.shape, 1)\n",
    "\n",
    "    y = np.zeros((x.shape[0], 1), dtype=float)\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            for k in range(W.shape[0]):\n",
    "                y[i][j] += x[i][k] * W[k][j] + b\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# trainig dataset\n",
    "x_data = np.array([1, 2, 3, 4, 5]).reshape(5, 1)\n",
    "t_data = np.array([2, 3, 4, 5, 6]).reshape(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[0.0516691]] , W.shape = (1, 1) , b = [0.1127704] , b.shape = (1,)\n"
     ]
    }
   ],
   "source": [
    "# random values of Weight\n",
    "W = np.random.rand(1, 1)\n",
    "\n",
    "# random values of Bias\n",
    "b = np.random.rand(1)\n",
    "\n",
    "print(\"W =\", W, \", W.shape =\", W.shape, \", b =\", b, \", b.shape =\", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value = [15.72814635] Initial W = [[0.0516691]] \n",
      " Initial b = [0.1127704]\n",
      "step = 0 error value = [9.28122085] W = [[0.31353567]] , b = [0.17170285]\n",
      "step = 400 error value = [0.00478013] W = [[1.04489693]] , b = [0.83794752]\n",
      "step = 800 error value = [0.000305] W = [[1.01134089]] , b = [0.95906582]\n",
      "step = 1200 error value = [1.94608408e-05] W = [[1.00286469]] , b = [0.98966009]\n",
      "step = 1600 error value = [1.2417167e-06] W = [[1.00072362]] , b = [0.99738816]\n",
      "step = 2000 error value = [7.92288662e-08] W = [[1.00018278]] , b = [0.99934025]\n",
      "step = 2400 error value = [5.05527006e-09] W = [[1.00004617]] , b = [0.99983335]\n",
      "step = 2800 error value = [3.22556117e-10] W = [[1.00001166]] , b = [0.9999579]\n",
      "step = 3200 error value = [2.05809872e-11] W = [[1.00000295]] , b = [0.99998937]\n",
      "step = 3600 error value = [1.31318866e-12] W = [[1.00000074]] , b = [0.99999731]\n",
      "step = 4000 error value = [8.37892e-14] W = [[1.00000019]] , b = [0.99999932]\n",
      "step = 4400 error value = [5.34624637e-15] W = [[1.00000005]] , b = [0.99999983]\n",
      "step = 4800 error value = [3.41122125e-16] W = [[1.00000001]] , b = [0.99999996]\n",
      "step = 5200 error value = [2.17656106e-17] W = [[1.]] , b = [0.99999999]\n",
      "step = 5600 error value = [1.38877456e-18] W = [[1.]] , b = [1.]\n",
      "step = 6000 error value = [8.86120827e-20] W = [[1.]] , b = [1.]\n",
      "step = 6400 error value = [5.65396609e-21] W = [[1.]] , b = [1.]\n",
      "step = 6800 error value = [3.60758937e-22] W = [[1.]] , b = [1.]\n",
      "step = 7200 error value = [2.30207631e-23] W = [[1.]] , b = [1.]\n",
      "step = 7600 error value = [1.46949187e-24] W = [[1.]] , b = [1.]\n",
      "step = 8000 error value = [9.3995814e-26] W = [[1.]] , b = [1.]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value =\", error_val(x_data, t_data), \"Initial W =\", W, \"\\n\", \"Initial b =\", b)\n",
    "\n",
    "for step in range(8001):\n",
    "    for i in range(W.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            W[i][j] -= learning_rate * numerical_derivative(f, W)[i][j]\n",
    "\n",
    "    for i in range(b.shape[0]):\n",
    "        b[i] -= learning_rate * numerical_derivative(f, b)[i]\n",
    "    \n",
    "    if step % 400 == 0:\n",
    "        print(\"step =\", step, \"error value =\", error_val(x_data, t_data), \"W =\", W, \", b =\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-variable Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "loaded_data = np.loadtxt('./data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = loaded_data[:, 0:-1]\n",
    "t_data = loaded_data[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[0.22363612]\n",
      " [0.8833373 ]\n",
      " [0.73641872]] , W.shape = (3, 1) , b = [0.96413167] , b.shape = (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(3, 1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W =\", W, \", W.shape =\", W.shape, \", b =\", b, \", b.shape =\", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value = [144.21206206] Initial W = [[0.22363612]\n",
      " [0.8833373 ]\n",
      " [0.73641872]] \n",
      " Initial b = [0.96413167]\n",
      "step = 0 error value = [69.42265347] W = [[0.2419813 ]\n",
      " [0.899242  ]\n",
      " [0.75092069]] , b = [0.96457355]\n",
      "step = 400 error value = [10.86528265] W = [[0.28072365]\n",
      " [0.86446006]\n",
      " [0.83898313]] , b = [0.96299988]\n",
      "step = 800 error value = [9.58093517] W = [[0.28475526]\n",
      " [0.80972824]\n",
      " [0.88863444]] , b = [0.9603996]\n",
      "step = 1200 error value = [8.69881495] W = [[0.28900841]\n",
      " [0.7640145 ]\n",
      " [0.92926453]] , b = [0.95766147]\n",
      "step = 1600 error value = [8.09208641] W = [[0.29335155]\n",
      " [0.72580551]\n",
      " [0.96247885]] , b = [0.95481153]\n",
      "step = 2000 error value = [7.67400882] W = [[0.29768533]\n",
      " [0.69384491]\n",
      " [0.98960066]] , b = [0.95187117]\n",
      "step = 2400 error value = [7.38524709] W = [[0.30193608]\n",
      " [0.66708934]\n",
      " [1.0117203 ]] , b = [0.94885795]\n",
      "step = 2800 error value = [7.1852001] W = [[0.30605052]\n",
      " [0.64467205]\n",
      " [1.02973587]] , b = [0.9457863]\n",
      "step = 3200 error value = [7.04607455] W = [[0.30999143]\n",
      " [0.62587276]\n",
      " [1.04438684]] , b = [0.94266802]\n",
      "step = 3600 error value = [6.9488349] W = [[0.31373421]\n",
      " [0.61009268]\n",
      " [1.05628179]] , b = [0.93951279]\n",
      "step = 4000 error value = [6.88043549] W = [[0.31726404]\n",
      " [0.59683383]\n",
      " [1.06592139]] , b = [0.93632852]\n",
      "step = 4400 error value = [6.83192866] W = [[0.32057365]\n",
      " [0.58568185]\n",
      " [1.0737173 ]] , b = [0.93312171]\n",
      "step = 4800 error value = [6.7971715] W = [[0.32366151]\n",
      " [0.57629183]\n",
      " [1.0800078 ]] , b = [0.92989762]\n",
      "step = 5200 error value = [6.77194172] W = [[0.32653036]\n",
      " [0.56837655]\n",
      " [1.08507071]] , b = [0.92666058]\n",
      "step = 5600 error value = [6.75333302] W = [[0.32918609]\n",
      " [0.56169663]\n",
      " [1.08913405]] , b = [0.92341408]\n",
      "step = 6000 error value = [6.7393415] W = [[0.33163682]\n",
      " [0.55605251]\n",
      " [1.0923848 ]] , b = [0.92016099]\n",
      "step = 6400 error value = [6.72858265] W = [[0.33389218]\n",
      " [0.5512777 ]\n",
      " [1.09497621]] , b = [0.91690362]\n",
      "step = 6800 error value = [6.7200976] W = [[0.33596274]\n",
      " [0.54723321]\n",
      " [1.09703371]] , b = [0.91364384]\n",
      "step = 7200 error value = [6.71322037] W = [[0.33785962]\n",
      " [0.54380293]\n",
      " [1.09865989]] , b = [0.91038316]\n",
      "step = 7600 error value = [6.70748688] W = [[0.33959413]\n",
      " [0.54088979]\n",
      " [1.09993856]] , b = [0.9071228]\n",
      "step = 8000 error value = [6.70257251] W = [[0.34117751]\n",
      " [0.53841258]\n",
      " [1.10093812]] , b = [0.90386374]\n",
      "step = 8400 error value = [6.6982492] W = [[0.34262078]\n",
      " [0.53630328]\n",
      " [1.10171428]] , b = [0.90060675]\n",
      "step = 8800 error value = [6.69435592] W = [[0.34393458]\n",
      " [0.5345049 ]\n",
      " [1.10231236]] , b = [0.89735248]\n",
      "step = 9200 error value = [6.69077835] W = [[0.3451291 ]\n",
      " [0.53296962]\n",
      " [1.10276917]] , b = [0.89410139]\n",
      "step = 9600 error value = [6.68743484] W = [[0.34621399]\n",
      " [0.53165728]\n",
      " [1.10311455]] , b = [0.89085389]\n",
      "step = 10000 error value = [6.68426666] W = [[0.34719837]\n",
      " [0.53053412]\n",
      " [1.10337262]] , b = [0.88761027]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value =\", error_val(x_data, t_data), \"Initial W =\", W, \"\\n\", \"Initial b =\", b)\n",
    "\n",
    "for step in range(10001):\n",
    "    for i in range(W.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            W[i][j] -= learning_rate * numerical_derivative(f, W)[i][j]\n",
    "\n",
    "    for i in range(b.shape[0]):\n",
    "        b[i] -= learning_rate * numerical_derivative(f, b)[i]\n",
    "    \n",
    "    if step % 400 == 0:\n",
    "        print(\"step =\", step, \"error value =\", error_val(x_data, t_data), \"W =\", W, \", b =\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[178.74819306]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81]).reshape(1, 3)\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Numpy 라이브러리를 이용하여 Batch 처리 방식으로 학습을 할 때보다 반복문(for-loop)을 통해 학습을 할 때 소요 시간이 상당히 긴 것을 알 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
